{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d973e4a-4636-4966-8f91-5b4906a9c7df",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59e4716e-a170-4e73-a7f3-30d9d8671e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3020504a-3bd1-4f6f-8267-649e6d525694",
   "metadata": {},
   "source": [
    "## Generating a URL with a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "e2954a16-fcbf-4add-ba3d-f25158a73a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the URL based on position, location, and page\n",
    "def generate_url(position, location, page=1):\n",
    "    base_url = \"https://www.careerjet.com/jobs\"\n",
    "    search_params = f\"?s={position.replace(' ', '+')}&l={location.replace(' ', '+')}&p={page}\"\n",
    "    return base_url + search_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5333c81-46a8-4b01-818d-5d7a7746335b",
   "metadata": {},
   "source": [
    "## Creating WebScraping Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "232b62ae-4502-44d3-bee4-d89f3c435140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape job postings based on position, location, and page\n",
    "def scrape_jobs(position, location, pages):\n",
    "    current_date = datetime.now().strftime(\"%Y-%m-%d\")  # Get current date to timestamp the CSV file\n",
    "    filename = f\"job_postings_{position.replace(' ', '_')}_{location.replace(' ', '_')}_{current_date}.csv\"\n",
    "    \n",
    "    # Open the CSV file for writing\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['JobTitle', 'Company', 'JobLocation', 'PostTime', 'ExtractDate', 'Salary', 'JobURL'])  # Write the header row\n",
    "        \n",
    "        for page in range(1, pages + 1):\n",
    "            url = generate_url(position, location, page)\n",
    "            print(f'url page{page}: {url}')\n",
    "            # Send a GET request to the generated URL\n",
    "            response = requests.get(url)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                job_listings = soup.find(\"ul\", class_=\"jobs\")  # Adjust selector based on actual page structure\n",
    "                job_listings = job_listings.find_all('li', class_= lambda x: x != 'cjgad-outer') #extract job listings\n",
    "\n",
    "                for job in job_listings:\n",
    "                        \n",
    "                    JobTitle = job.find('h2').find('a').text.strip() if job.find('h2') else None\n",
    "    \n",
    "                    company_tag = job.find('p', class_='company')\n",
    "                    Company = company_tag.find('a').text.strip() if company_tag and company_tag.find('a') else None\n",
    "                    \n",
    "                    JobLocation = job.find('ul', class_='location').find('li').text.strip() if job.find('ul', class_='location') else None\n",
    "                    \n",
    "                    PostTime = job.find('footer').find('ul', class_='tags').find('li').find('span').text.strip() if job.find('footer') else None\n",
    "                    \n",
    "                    ExtractDate = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "                    \n",
    "                    Salary = job.find('ul', class_='salary').find('li').text.strip() if job.find('ul', class_='salary') else None\n",
    "                  \n",
    "                    JobURL = \"https://www.careerjet.com\" + job.find('h2').find('a').get('href') if job.find('h2') else None\n",
    "    \n",
    "                    values =  [JobTitle, Company, JobLocation, PostTime, ExtractDate, Salary, JobURL]\n",
    "                    if None not in values:\n",
    "                        writer.writerow(values)\n",
    "                                               \n",
    "                # Introduce a delay between requests (avoid overloading the server)\n",
    "                time.sleep(1)\n",
    "            else:\n",
    "                print(f\"Failed to retrieve the page {page}. Status code: {response.status_code}\")\n",
    "\n",
    "    print(f\"\\nJob postings saved to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd838b8-9660-4e80-a0a2-f7848874d62f",
   "metadata": {},
   "source": [
    "## Testing the Code with JobTitle: `Data Analyst`, Location: `New York`, Maxpages: `3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "1fc18d14-2073-4f96-8276-e720c79ccbe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url page1: https://www.careerjet.com/jobs?s=Data+Analyst&l=New+York&p=1\n",
      "url page2: https://www.careerjet.com/jobs?s=Data+Analyst&l=New+York&p=2\n",
      "url page3: https://www.careerjet.com/jobs?s=Data+Analyst&l=New+York&p=3\n",
      "\n",
      "Job postings saved to job_postings_Data_Analyst_New_York_2025-02-08.csv\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "JobTitle = \"Data Analyst\"\n",
    "Location = \"New York\"\n",
    "Maxpages = 3\n",
    "\n",
    "scrape_jobs(JobTitle, Location, Maxpages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
